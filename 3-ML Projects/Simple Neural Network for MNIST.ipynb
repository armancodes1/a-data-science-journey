{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66043526",
   "metadata": {
    "papermill": {
     "duration": 0.012295,
     "end_time": "2020-11-24T15:33:44.585418",
     "exception": false,
     "start_time": "2020-11-24T15:33:44.573123",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Simple Neural Network for MNIST "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f826f43-cd28-4139-8282-0fe3f21dd616",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4449873-932c-4175-b0f5-59c62469929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7f343a-d57a-43de-8285-a4967e8b2ee0",
   "metadata": {},
   "source": [
    "## 2. Load Data and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b67c2fd-c1ac-40b3-965f-449f38b9cf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST (using sklearn )\n",
    "print(\"Loading data...\")\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False, parser='auto')\n",
    "\n",
    "# Use a subset (2000 samples) for speed and normalize pixel values (0-255 -> 0-1)\n",
    "X_raw = mnist.data[:2000] / 255.0  \n",
    "y_raw = mnist.target[:2000].astype(int)\n",
    "\n",
    "# One-Hot Encode Y (Convert label '3' to [0,0,0,1,0...])\n",
    "n_values = 10\n",
    "Y_ohe = np.eye(n_values)[y_raw] \n",
    "\n",
    "# Transpose to match shape structure: (Features, Examples)\n",
    "X = X_raw.T       # (784, 2000)\n",
    "Y = Y_ohe.T       # (10, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13053b0-430b-49f5-9006-80ff2f9d9b66",
   "metadata": {},
   "source": [
    "## 3. Activation Functions Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7a4e755-b574-4be0-8e45-85c7ad9e5aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    return 1 / (1 + np.exp(-Z))\n",
    "\n",
    "def sigmoid_deriv(A):\n",
    "    return A * (1 - A)\n",
    "\n",
    "# Softmax for multi-class output\n",
    "def softmax(Z):\n",
    "    expZ = np.exp(Z - np.max(Z, axis=0, keepdims=True)) # Subtract max for stability\n",
    "    return expZ / np.sum(expZ, axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cf1c8c-380b-40eb-9b7f-fd189d824969",
   "metadata": {},
   "source": [
    "## 4. Neural Network\n",
    "- **Input layer** $a^{[0]}$: 784 units `(28*28*1 pixels)`\n",
    "- **Hidden layer** $a^{[1]}$: 64 units, sigmoid activation  \n",
    "- **Output layer** $a^{[2]}$: 10 unit, softmax activation (multiclass output)\n",
    "\n",
    "---\n",
    "\n",
    "## 4.1 Forward Propagation\n",
    "\n",
    "$$\n",
    "Z^{[1]} = W^{[1]} X + b^{[1]}\n",
    "$$\n",
    "\n",
    "$$\n",
    "A^{[1]} = \\sigma_{\\text{ReLU}}(Z^{[1]}))\n",
    "$$\n",
    "\n",
    "$$\n",
    "Z^{[2]} = W^{[2]} A^{[1]} + b^{[2]}\n",
    "$$\n",
    "\n",
    "$$\n",
    "A^{[2]} = \\sigma_{\\text{softmax}}(Z^{[2]})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a22c041-3aac-481d-a86a-872fa2299bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters Initialization\n",
    "def init_params(n_x, n_h, n_y):\n",
    "    np.random.seed(1)\n",
    "    W1 = np.random.randn(n_h, n_x) * 0.1\n",
    "    b1 = np.zeros((n_h, 1))\n",
    "    W2 = np.random.randn(n_y, n_h) * 0.1\n",
    "    b2 = np.zeros((n_y, 1))\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "# Forward propagation\n",
    "def forward_prop(W1, b1, W2, b2, X):\n",
    "    Z1 = W1.dot(X) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = softmax(Z2) # Softmax for 10 classes\n",
    "    return Z1, A1, Z2, A2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b530fe0-d2f9-46aa-bb53-4db0b845c40d",
   "metadata": {},
   "source": [
    "## 4.2 Backward Propagation\n",
    "\n",
    "$$\n",
    "dZ^{[2]} = A^{[2]} - Y\n",
    "$$\n",
    "\n",
    "$$\n",
    "dW^{[2]} = \\frac{1}{m} \\, dZ^{[2]} A^{[1]T}\n",
    "$$\n",
    "\n",
    "$$\n",
    "db^{[2]} = \\frac{1}{m} \\sum dZ^{[2]}\n",
    "$$\n",
    "\n",
    "$$\n",
    "dZ^{[1]} = W^{[2]T} dZ^{[2]} \\circ \\sigma'_{\\text{ReLU}}(A^{[1]}))\n",
    "$$\n",
    "\n",
    "$$\n",
    "dW^{[1]} = \\frac{1}{m} \\, dZ^{[1]} A^{[0]T}\n",
    "$$\n",
    "\n",
    "$$\n",
    "db^{[1]} = \\frac{1}{m} \\sum dZ^{[1]}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35f5278c-9ee1-4813-b0b7-9dd86fe26c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward propagation\n",
    "def backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y):\n",
    "    m = X.shape[1]\n",
    "\n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = (1/m) * dZ2.dot(A1.T)\n",
    "    db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "\n",
    "    dA1 = W2.T.dot(dZ2)\n",
    "    dZ1 = dA1 * sigmoid_deriv(A1)\n",
    "    dW1 = (1/m) * dZ1.dot(X.T)\n",
    "    db1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "    return dW1, db1, dW2, db2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c627b3fc-f040-4654-b8eb-6a593e932dd7",
   "metadata": {},
   "source": [
    "## 4.3 Parameter Updates\n",
    "\n",
    "$$\n",
    "W^{[2]} := W^{[2]} - \\alpha \\, dW^{[2]}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b^{[2]} := b^{[2]} - \\alpha \\, db^{[2]}\n",
    "$$\n",
    "\n",
    "$$\n",
    "W^{[1]} := W^{[1]} - \\alpha \\, dW^{[1]}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b^{[1]} := b^{[1]} - \\alpha \\, db^{[1]}\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db9a82de-b097-4aed-86a2-526a0b9db565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update weights\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "    W1 -= alpha * dW1\n",
    "    b1 -= alpha * db1\n",
    "    W2 -= alpha * dW2\n",
    "    b2 -= alpha * db2\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "# Prediction\n",
    "def predict(X, W1, b1, W2, b2):\n",
    "    _, _, _, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "    return np.argmax(A2, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f88ea5-c3a6-4446-bc25-7182643bd2df",
   "metadata": {},
   "source": [
    "## 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe975ddc-f0dd-49ae-beed-5b92bfd93cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0   Accuracy: 15.35%\n",
      "Iteration 100   Accuracy: 87.10%\n",
      "Iteration 200   Accuracy: 91.30%\n",
      "Iteration 300   Accuracy: 93.50%\n",
      "Iteration 400   Accuracy: 94.95%\n",
      "Iteration 500   Accuracy: 95.55%\n",
      "Iteration 600   Accuracy: 96.05%\n",
      "Iteration 700   Accuracy: 96.85%\n",
      "Iteration 800   Accuracy: 97.60%\n",
      "Iteration 900   Accuracy: 98.10%\n",
      "Iteration 1000   Accuracy: 98.50%\n"
     ]
    }
   ],
   "source": [
    "# Training loop \n",
    "def gradient_descent(X, Y, iterations=1000, alpha=0.5):\n",
    "    n_x = X.shape[0] # 784\n",
    "    n_h = 64         # hidden layer neurons\n",
    "    n_y = 10         # 10 output classes\n",
    "\n",
    "    W1, b1, W2, b2 = init_params(n_x, n_h, n_y)\n",
    "\n",
    "    # Convert One-Hot Y back to labels for accuracy checking\n",
    "    Y_labels = np.argmax(Y, axis=0)\n",
    "\n",
    "    for i in range(iterations + 1):\n",
    "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "        dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y)\n",
    "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            predictions = predict(X, W1, b1, W2, b2)\n",
    "            acc = np.mean(predictions == Y_labels)\n",
    "            print(f\"Iteration {i}   Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "# Train\n",
    "W1, b1, W2, b2 = gradient_descent(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8ad5c9-9185-484b-8b23-9bf6a14ec6f5",
   "metadata": {},
   "source": [
    "## 6. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "723be39b-f639-459a-b4b1-5d1d2942e093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 20 Predictions: [5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9]\n",
      "First 20 True Labels: [5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9]\n"
     ]
    }
   ],
   "source": [
    "# Final Prediction Check\n",
    "preds = predict(X, W1, b1, W2, b2)\n",
    "print(\"\\nFirst 20 Predictions:\", preds[:20])\n",
    "print(\"First 20 True Labels:\", np.argmax(Y, axis=0)[:20])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "duration": 55.320944,
   "end_time": "2020-11-24T15:34:35.258832",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-24T15:33:39.937888",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
